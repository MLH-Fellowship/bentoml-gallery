{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "paddlepaddle.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erfOlc-T8kY3"
      },
      "source": [
        "# **BentoML Example: Linear Regression with Paddlepaddle**\n",
        "**BentoML makes moving trained ML models to production easy:**\n",
        "\n",
        "\n",
        "\n",
        "*   Package models trained with any ML framework and reproduce them for model serving in production\n",
        "* **Deploy anywhere** for online API serving or offline batch serving\n",
        "* High-Performance API model server with adaptive micro-batching support\n",
        "* Central hub for managing models and deployment process via Web UI and APIs\n",
        "* Modular and flexible design making it adaptable to your infrastrcuture\n",
        "\n",
        "BentoML is a framework for serving, managing, and deploying machine learning models. It is aiming to bridge the gap between Data Science and DevOps, and enable teams to deliver prediction services in a fast, repeatable, and scalable way.\n",
        "\n",
        "Before reading this example project, be sure to check out the [Getting started guide](https://github.com/bentoml/BentoML/blob/master/guides/quick-start/bentoml-quick-start-guide.ipynb) to learn about the basic concepts in BentoML.\n",
        "\n",
        "This notebook demonstrates how to use BentoML to turn a paddlepaddle model into a docker image containing a REST API server serving this model, how to use your ML service built with BentoML as a CLI tool, and how to distribute it a pypi package.\n",
        "\n",
        "The example is based on [this tutorial](https://www.paddlepaddle.org.cn/documentation/docs/en/1.5/beginners_guide/basics/fit_a_line/README.html), using dataset from the [UCI Machine Learning Repository](https://www.kaggle.com/schirmerchad/bostonhoustingmlnd)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54jFhiru8NWO"
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHOPuMGm-Nl2",
        "outputId": "cc2a3ef8-e9d1-4ed8-d8df-a7c9b9d55fca"
      },
      "source": [
        "!pip install -q bentoml 'paddlepaddle>=2.0.0' 'pandas>=1.1.1' 'numpy>=1.8.2'\n",
        "\n",
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/MLH-Fellowship/BentoML.git@PaddleModelArtifact-test\n",
            "  Cloning https://github.com/MLH-Fellowship/BentoML.git (to revision PaddleModelArtifact-test) to /tmp/pip-req-build-vx_pz6nk\n",
            "  Running command git clone -q https://github.com/MLH-Fellowship/BentoML.git /tmp/pip-req-build-vx_pz6nk\n",
            "  Running command git checkout -b PaddleModelArtifact-test --track origin/PaddleModelArtifact-test\n",
            "  Switched to a new branch 'PaddleModelArtifact-test'\n",
            "  Branch 'PaddleModelArtifact-test' set up to track remote branch 'PaddleModelArtifact-test' from 'origin'.\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from BentoML==0.7.8+404.g2d929d6) (7.1.2)\n",
            "Collecting dependency-injector<5.0,>=4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/19/49c73737f3d71ccb2bc6fe07c19f3195faf6d085a9887c829e54f06c1a63/dependency_injector-4.29.2-cp37-cp37m-manylinux2010_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 4.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from BentoML==0.7.8+404.g2d929d6) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from BentoML==0.7.8+404.g2d929d6) (2.8.1)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/6d/1c43d87bfff9e7afb5130629dfb7d57617245eeb4a474bf77f45d637c3a6/boto3-1.17.33-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 29.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from BentoML==0.7.8+404.g2d929d6) (5.4.8)\n",
            "Collecting schema\n",
            "  Downloading https://files.pythonhosted.org/packages/c7/64/497632c9dc3c1bc94a92d9cafdc5cbd21d011bb651952765195739129a49/schema-0.7.4-py2.py3-none-any.whl\n",
            "Collecting configparser\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: sqlalchemy<1.4.0,>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from BentoML==0.7.8+404.g2d929d6) (1.3.23)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from BentoML==0.7.8+404.g2d929d6) (0.8.9)\n",
            "Collecting humanfriendly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/66/363d01a81da2108a5cf446daf619779f06d49a0c4426dd02b40734f10e2f/humanfriendly-9.1-py2.py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 8.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from BentoML==0.7.8+404.g2d929d6) (3.0.4)\n",
            "Collecting gunicorn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/ca/926f7cd3a2014b16870086b2d0fdc84a9e49473c68a8dff8b57f7c156f43/gunicorn-20.0.4-py2.py3-none-any.whl (77kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 6.8MB/s \n",
            "\u001b[?25hCollecting cerberus\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/a7/71c6ed2d46a81065e68c007ac63378b96fa54c7bb614d653c68232f9c50c/Cerberus-1.3.2.tar.gz (52kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.4MB/s \n",
            "\u001b[?25hCollecting ruamel.yaml>=0.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/c3/4c823dac2949a6baf36a4987d04c50d30184147393ba6f4bfb4c67d15a13/ruamel.yaml-0.16.13-py2.py3-none-any.whl (111kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 25.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from BentoML==0.7.8+404.g2d929d6) (2.23.0)\n",
            "Collecting py-zipkin\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/dd/7ef9b1aad9dace878f59ae0629f2881bbf0def7446252b24993dcfa39eed/py_zipkin-0.20.2-py2.py3-none-any.whl (52kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 4.9MB/s \n",
            "\u001b[?25hCollecting alembic\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/29/ed5c134aba874053859ba3e8d4705b4a5c1b66156deabc26cbe643e83f2e/alembic-1.5.7-py2.py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 19.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (from BentoML==0.7.8+404.g2d929d6) (1.1.2)\n",
            "Collecting sqlalchemy-utils<0.36.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/b2/84cda702d7253925f67212112838f3467907e7a0eeae1433a2b06db05e07/SQLAlchemy-Utils-0.36.7.tar.gz (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 25.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from BentoML==0.7.8+404.g2d929d6) (2020.12.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from BentoML==0.7.8+404.g2d929d6) (3.12.4)\n",
            "Collecting aiohttp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/c0/5890b4c8b04a79b7360e8fe4490feb0bb3ab179743f199f0e6220cebd568/aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 25.3MB/s \n",
            "\u001b[?25hCollecting deepmerge\n",
            "  Downloading https://files.pythonhosted.org/packages/72/89/3c310fb23c96ef2dcf8bab59dc500f53a06a1dd6d05ceec217331b097962/deepmerge-0.2.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from BentoML==0.7.8+404.g2d929d6) (20.9)\n",
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.7/dist-packages (from BentoML==0.7.8+404.g2d929d6) (1.32.0)\n",
            "Collecting docker\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c4/22/410313ad554477e87ec406d38d85f810e61ddb0d2fc44e64994857476de9/docker-4.4.4-py2.py3-none-any.whl (147kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 43.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from BentoML==0.7.8+404.g2d929d6) (0.9.0)\n",
            "Collecting python-json-logger\n",
            "  Downloading https://files.pythonhosted.org/packages/bd/95/ccbae460a4db2610b8d2635b5f1e7ed146fb771f4ef47ef20a1f216f9b78/python-json-logger-2.0.1.tar.gz\n",
            "Requirement already satisfied: urllib3<=1.25.11 in /usr/local/lib/python3.7/dist-packages (from BentoML==0.7.8+404.g2d929d6) (1.24.3)\n",
            "Requirement already satisfied: six<=1.15.0,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from dependency-injector<5.0,>=4.0->BentoML==0.7.8+404.g2d929d6) (1.15.0)\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/14/0b4be62b65c52d6d1c442f24e02d2a9889a73d3c352002e14c70f84a679f/s3transfer-0.3.6-py2.py3-none-any.whl (73kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 7.2MB/s \n",
            "\u001b[?25hCollecting botocore<1.21.0,>=1.20.33\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/1c/f922d7fa47cdd6a18c7470252e86f7c4d24e85cb3cdff09486675df3769c/botocore-1.20.33-py2.py3-none-any.whl (7.3MB)\n",
            "\u001b[K     |████████████████████████████████| 7.3MB 36.2MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: contextlib2>=0.5.5 in /usr/local/lib/python3.7/dist-packages (from schema->BentoML==0.7.8+404.g2d929d6) (0.5.5)\n",
            "Requirement already satisfied: setuptools>=3.0 in /usr/local/lib/python3.7/dist-packages (from gunicorn->BentoML==0.7.8+404.g2d929d6) (54.1.2)\n",
            "Collecting ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.10\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/6e/f652c56bbb2c3d3fca252ffc7c0358597f57a1bbdf484dac683054950c63/ruamel.yaml.clib-0.2.2-cp37-cp37m-manylinux1_x86_64.whl (547kB)\n",
            "\u001b[K     |████████████████████████████████| 552kB 41.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->BentoML==0.7.8+404.g2d929d6) (2.10)\n",
            "Collecting thriftpy2>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/d1/6b041449bd04b953294f3a070fc96bd8ce23ff81e96cc4c2920f7d555fe0/thriftpy2-0.4.14.tar.gz (361kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 40.1MB/s \n",
            "\u001b[?25hCollecting Mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/54/dbc07fbb20865d3b78fdb7cf7fa713e2cba4f87f71100074ef2dc9f9d1f7/Mako-1.1.4-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 7.5MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask->BentoML==0.7.8+404.g2d929d6) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask->BentoML==0.7.8+404.g2d929d6) (1.0.1)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask->BentoML==0.7.8+404.g2d929d6) (2.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->BentoML==0.7.8+404.g2d929d6) (3.7.4.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->BentoML==0.7.8+404.g2d929d6) (20.3.0)\n",
            "Collecting async-timeout<4.0,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
            "Collecting yarl<2.0,>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/62/046834c5fc998c88ab2ef722f5d42122230a632212c8afa76418324f53ff/yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 36.7MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a6/4123b8165acbe773d1a8dc8e3f0d1edea16d29f7de018eda769abb56bd30/multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 46.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->BentoML==0.7.8+404.g2d929d6) (2.4.7)\n",
            "Collecting websocket-client>=0.32.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/33/80e0d4f60e84a1ddd9a03f340be1065a2a363c47ce65c4bd3bae65ce9631/websocket_client-0.58.0-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.5MB/s \n",
            "\u001b[?25hCollecting ply<4.0,>=3.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/58/35da89ee790598a0700ea49b2a66594140f44dec458c07e8e3d4979137fc/ply-3.11-py2.py3-none-any.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->BentoML==0.7.8+404.g2d929d6) (1.1.1)\n",
            "Building wheels for collected packages: BentoML\n",
            "  Building wheel for BentoML (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for BentoML: filename=BentoML-0.7.8+404.g2d929d6-cp37-none-any.whl size=1129579 sha256=29e49e266646466e26e7df306b37ef09a669d45159a8d5e299e8a8a5d451980d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3__ch28i/wheels/ac/eb/44/b957105e7ed47240145e85763ed24cba722de81bbe65b53152\n",
            "Successfully built BentoML\n",
            "Building wheels for collected packages: cerberus, sqlalchemy-utils, python-json-logger, thriftpy2\n",
            "  Building wheel for cerberus (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cerberus: filename=Cerberus-1.3.2-cp37-none-any.whl size=54336 sha256=8561a8b4e861a1032a4091b8b086be601346bea350e33ce3a969315cc51fbbf6\n",
            "  Stored in directory: /root/.cache/pip/wheels/e9/38/1f/f2cc84182676f3ae7134b9b2d744f9c235b24d2ddc8f7fe465\n",
            "  Building wheel for sqlalchemy-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlalchemy-utils: filename=SQLAlchemy_Utils-0.36.7-py2.py3-none-any.whl size=93226 sha256=0b16347abd5c6040877db3583258e20d4e90632edccc1006a033d98432aae595\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/5b/cc/cc61388e74ca38739b64cb723efce6b623975b5c9a32ba7504\n",
            "  Building wheel for python-json-logger (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-json-logger: filename=python_json_logger-2.0.1-cp37-none-any.whl size=7375 sha256=60cf95844a5b5b77dc2f8dd233014c2477d60adf5988c30cb03125ec4b1d626e\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/fe/d0/53a8a9f614e3d7b7b8025fac655abd7a8bf86e0980c9956030\n",
            "  Building wheel for thriftpy2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for thriftpy2: filename=thriftpy2-0.4.14-cp37-cp37m-linux_x86_64.whl size=940266 sha256=7afff16384f258c6f4d3ab61233eb609be925f4ad7f3a84428364ed9d4fb7e92\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/c6/6b/c94a9a90153934a39a26ed4d94254d0e347b706f989b526c8b\n",
            "Successfully built cerberus sqlalchemy-utils python-json-logger thriftpy2\n",
            "\u001b[31mERROR: botocore 1.20.33 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: dependency-injector, jmespath, botocore, s3transfer, boto3, schema, configparser, humanfriendly, gunicorn, cerberus, ruamel.yaml.clib, ruamel.yaml, ply, thriftpy2, py-zipkin, Mako, python-editor, alembic, sqlalchemy-utils, async-timeout, multidict, yarl, aiohttp, deepmerge, websocket-client, docker, python-json-logger, BentoML\n",
            "Successfully installed BentoML-0.7.8+404.g2d929d6 Mako-1.1.4 aiohttp-3.7.4.post0 alembic-1.5.7 async-timeout-3.0.1 boto3-1.17.33 botocore-1.20.33 cerberus-1.3.2 configparser-5.0.2 deepmerge-0.2.1 dependency-injector-4.29.2 docker-4.4.4 gunicorn-20.0.4 humanfriendly-9.1 jmespath-0.10.0 multidict-5.1.0 ply-3.11 py-zipkin-0.20.2 python-editor-1.0.4 python-json-logger-2.0.1 ruamel.yaml-0.16.13 ruamel.yaml.clib-0.2.2 s3transfer-0.3.6 schema-0.7.4 sqlalchemy-utils-0.36.7 thriftpy2-0.4.14 websocket-client-0.58.0 yarl-1.6.3\n",
            "Collecting paddlepaddle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/ad/c1705be6b25a7f0413c4931636c6d1a9752f4383bd00eb62c353be9133f7/paddlepaddle-2.0.1-cp37-cp37m-manylinux1_x86_64.whl (208.1MB)\n",
            "\u001b[K     |████████████████████████████████| 208.1MB 67kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13; python_version >= \"3.5\" and platform_system != \"Windows\" in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (1.19.5)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (2.23.0)\n",
            "Requirement already satisfied: gast>=0.3.3; platform_system != \"Windows\" in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (0.3.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (7.0.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (4.4.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (1.15.0)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (3.12.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle) (1.24.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.1.0->paddlepaddle) (54.1.2)\n",
            "Installing collected packages: paddlepaddle\n",
            "Successfully installed paddlepaddle-2.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTmhsmvk-iZT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfa742ff-7c1a-4e87-bb76-0b22fadb1c76"
      },
      "source": [
        "import numpy as np\n",
        "import paddle\n",
        "import paddle.nn as nn\n",
        "import paddle.optimizer as opt\n",
        "import pandas as pd\n",
        "\n",
        "import bentoml"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-19 23:33:06,316 - INFO - No local BentoML config file found, using default configurations\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CeOjFaR_e2x"
      },
      "source": [
        "# **Prepare Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yayroXhE-sos",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab3c71be-bf63-4943-f731-d872ae81ad8d"
      },
      "source": [
        "import paddle\n",
        "import numpy as np\n",
        "import bentoml\n",
        "from paddle.static import InputSpec\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "BATCH_NUM = 4\n",
        "EPOCH_NUM = 5\n",
        "\n",
        "IN_FEATURES = 13\n",
        "OUT_FEATURES = 1\n",
        "\n",
        "class LinearNet(paddle.nn.Layer):\n",
        "    def __init__(self):\n",
        "        super(LinearNet, self).__init__()\n",
        "        self._linear = paddle.nn.Linear(IN_FEATURES, OUT_FEATURES)\n",
        "\n",
        "    @paddle.jit.to_static(input_spec=[InputSpec(shape=[IN_FEATURES], dtype='float32')])\n",
        "    def forward(self, x):\n",
        "        return self._linear(x)\n",
        "\n",
        "    def train(self, loader, loss_fn, opt):\n",
        "        for epoch_id in range(EPOCH_NUM):\n",
        "            for batch_id, (image, label) in enumerate(loader()):\n",
        "                out = self._linear(image)\n",
        "                loss = loss_fn(out, label)\n",
        "                loss.backward()\n",
        "                opt.step()\n",
        "                opt.clear_grad()\n",
        "                print(\"Epoch {} batch {}: loss = {}\".format(\n",
        "                    epoch_id, batch_id, np.mean(loss.numpy())))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/paddle/fluid/layers/utils.py:77: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
            "  return (isinstance(seq, collections.Sequence) and\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEiqsFpJ_qk-"
      },
      "source": [
        "# **Model Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hhiqk3VP_mqe",
        "outputId": "a9140bcf-769b-453f-d2bf-f90a4581efd2"
      },
      "source": [
        "model = LinearNet()\n",
        "loss_fn = paddle.nn.MSELoss()\n",
        "adam = paddle.optimizer.Adam(parameters=model.parameters())\n",
        "\n",
        "dataset = paddle.text.datasets.UCIHousing(mode=\"train\")\n",
        "\n",
        "loader = paddle.io.DataLoader(dataset,\n",
        "  batch_size=BATCH_SIZE,\n",
        "  shuffle=True,\n",
        "  drop_last=True,\n",
        "  num_workers=2)\n",
        "\n",
        "model.train(loader, loss_fn, adam)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cache file /root/.cache/paddle/dataset/uci_housing/housing.data not found, downloading http://paddlemodels.bj.bcebos.com/uci_housing/housing.data \n",
            "Begin to download\n",
            "............\n",
            "Download finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 batch 0: loss = 489.1203308105469\n",
            "Epoch 0 batch 1: loss = 599.2152099609375\n",
            "Epoch 0 batch 2: loss = 339.50299072265625\n",
            "Epoch 0 batch 3: loss = 698.6666259765625\n",
            "Epoch 0 batch 4: loss = 697.6690673828125\n",
            "Epoch 0 batch 5: loss = 570.4569091796875\n",
            "Epoch 0 batch 6: loss = 465.7235107421875\n",
            "Epoch 0 batch 7: loss = 671.98193359375\n",
            "Epoch 0 batch 8: loss = 827.1461791992188\n",
            "Epoch 0 batch 9: loss = 450.97784423828125\n",
            "Epoch 0 batch 10: loss = 855.7215576171875\n",
            "Epoch 0 batch 11: loss = 560.093017578125\n",
            "Epoch 0 batch 12: loss = 722.340087890625\n",
            "Epoch 0 batch 13: loss = 420.76055908203125\n",
            "Epoch 0 batch 14: loss = 619.928955078125\n",
            "Epoch 0 batch 15: loss = 716.5411376953125\n",
            "Epoch 0 batch 16: loss = 782.0941162109375\n",
            "Epoch 0 batch 17: loss = 449.8642272949219\n",
            "Epoch 0 batch 18: loss = 873.098388671875\n",
            "Epoch 0 batch 19: loss = 573.3613891601562\n",
            "Epoch 0 batch 20: loss = 734.6273193359375\n",
            "Epoch 0 batch 21: loss = 1010.7808837890625\n",
            "Epoch 0 batch 22: loss = 680.0187377929688\n",
            "Epoch 0 batch 23: loss = 406.7107238769531\n",
            "Epoch 0 batch 24: loss = 781.9826049804688\n",
            "Epoch 0 batch 25: loss = 518.58984375\n",
            "Epoch 0 batch 26: loss = 889.6790771484375\n",
            "Epoch 0 batch 27: loss = 789.8382568359375\n",
            "Epoch 0 batch 28: loss = 624.1957397460938\n",
            "Epoch 0 batch 29: loss = 684.5797119140625\n",
            "Epoch 0 batch 30: loss = 806.40234375\n",
            "Epoch 0 batch 31: loss = 367.18463134765625\n",
            "Epoch 0 batch 32: loss = 1015.6097412109375\n",
            "Epoch 0 batch 33: loss = 544.86181640625\n",
            "Epoch 0 batch 34: loss = 602.6260375976562\n",
            "Epoch 0 batch 35: loss = 390.50244140625\n",
            "Epoch 0 batch 36: loss = 605.08056640625\n",
            "Epoch 0 batch 37: loss = 711.53369140625\n",
            "Epoch 0 batch 38: loss = 571.3057861328125\n",
            "Epoch 0 batch 39: loss = 693.4288330078125\n",
            "Epoch 0 batch 40: loss = 1075.571533203125\n",
            "Epoch 0 batch 41: loss = 702.5487060546875\n",
            "Epoch 0 batch 42: loss = 599.5338745117188\n",
            "Epoch 0 batch 43: loss = 758.7379150390625\n",
            "Epoch 0 batch 44: loss = 1052.340087890625\n",
            "Epoch 0 batch 45: loss = 832.2259521484375\n",
            "Epoch 0 batch 46: loss = 668.7508544921875\n",
            "Epoch 0 batch 47: loss = 670.6744384765625\n",
            "Epoch 0 batch 48: loss = 406.9057922363281\n",
            "Epoch 0 batch 49: loss = 674.2766723632812\n",
            "Epoch 1 batch 0: loss = 463.07049560546875\n",
            "Epoch 1 batch 1: loss = 398.13323974609375\n",
            "Epoch 1 batch 2: loss = 801.28955078125\n",
            "Epoch 1 batch 3: loss = 659.5015258789062\n",
            "Epoch 1 batch 4: loss = 584.1564331054688\n",
            "Epoch 1 batch 5: loss = 675.9522094726562\n",
            "Epoch 1 batch 6: loss = 665.184814453125\n",
            "Epoch 1 batch 7: loss = 486.3677062988281\n",
            "Epoch 1 batch 8: loss = 622.4239501953125\n",
            "Epoch 1 batch 9: loss = 380.2066650390625\n",
            "Epoch 1 batch 10: loss = 527.5286254882812\n",
            "Epoch 1 batch 11: loss = 737.6890869140625\n",
            "Epoch 1 batch 12: loss = 648.5158081054688\n",
            "Epoch 1 batch 13: loss = 451.167724609375\n",
            "Epoch 1 batch 14: loss = 716.235595703125\n",
            "Epoch 1 batch 15: loss = 553.6993408203125\n",
            "Epoch 1 batch 16: loss = 471.345458984375\n",
            "Epoch 1 batch 17: loss = 736.333984375\n",
            "Epoch 1 batch 18: loss = 1008.5496826171875\n",
            "Epoch 1 batch 19: loss = 782.3773193359375\n",
            "Epoch 1 batch 20: loss = 471.98748779296875\n",
            "Epoch 1 batch 21: loss = 341.89013671875\n",
            "Epoch 1 batch 22: loss = 488.2086181640625\n",
            "Epoch 1 batch 23: loss = 556.4334716796875\n",
            "Epoch 1 batch 24: loss = 556.134521484375\n",
            "Epoch 1 batch 25: loss = 452.1860656738281\n",
            "Epoch 1 batch 26: loss = 467.8023986816406\n",
            "Epoch 1 batch 27: loss = 366.45037841796875\n",
            "Epoch 1 batch 28: loss = 717.7066650390625\n",
            "Epoch 1 batch 29: loss = 1073.1494140625\n",
            "Epoch 1 batch 30: loss = 616.2897338867188\n",
            "Epoch 1 batch 31: loss = 1312.806396484375\n",
            "Epoch 1 batch 32: loss = 568.23681640625\n",
            "Epoch 1 batch 33: loss = 875.4944458007812\n",
            "Epoch 1 batch 34: loss = 351.2110595703125\n",
            "Epoch 1 batch 35: loss = 579.733154296875\n",
            "Epoch 1 batch 36: loss = 669.88671875\n",
            "Epoch 1 batch 37: loss = 780.5726318359375\n",
            "Epoch 1 batch 38: loss = 635.5812377929688\n",
            "Epoch 1 batch 39: loss = 410.06536865234375\n",
            "Epoch 1 batch 40: loss = 999.3495483398438\n",
            "Epoch 1 batch 41: loss = 610.512939453125\n",
            "Epoch 1 batch 42: loss = 830.7664794921875\n",
            "Epoch 1 batch 43: loss = 1094.3887939453125\n",
            "Epoch 1 batch 44: loss = 645.134765625\n",
            "Epoch 1 batch 45: loss = 1126.9625244140625\n",
            "Epoch 1 batch 46: loss = 989.2822265625\n",
            "Epoch 1 batch 47: loss = 615.614990234375\n",
            "Epoch 1 batch 48: loss = 852.1439819335938\n",
            "Epoch 1 batch 49: loss = 755.4183349609375\n",
            "Epoch 2 batch 0: loss = 587.442626953125\n",
            "Epoch 2 batch 1: loss = 514.1015625\n",
            "Epoch 2 batch 2: loss = 446.2379455566406\n",
            "Epoch 2 batch 3: loss = 433.5572509765625\n",
            "Epoch 2 batch 4: loss = 530.28955078125\n",
            "Epoch 2 batch 5: loss = 395.8087463378906\n",
            "Epoch 2 batch 6: loss = 600.776611328125\n",
            "Epoch 2 batch 7: loss = 899.301025390625\n",
            "Epoch 2 batch 8: loss = 874.493896484375\n",
            "Epoch 2 batch 9: loss = 785.1796875\n",
            "Epoch 2 batch 10: loss = 922.143310546875\n",
            "Epoch 2 batch 11: loss = 535.2777099609375\n",
            "Epoch 2 batch 12: loss = 788.467529296875\n",
            "Epoch 2 batch 13: loss = 425.34759521484375\n",
            "Epoch 2 batch 14: loss = 873.0133056640625\n",
            "Epoch 2 batch 15: loss = 700.4376220703125\n",
            "Epoch 2 batch 16: loss = 780.6264038085938\n",
            "Epoch 2 batch 17: loss = 583.9261474609375\n",
            "Epoch 2 batch 18: loss = 507.547607421875\n",
            "Epoch 2 batch 19: loss = 511.0378723144531\n",
            "Epoch 2 batch 20: loss = 820.3839111328125\n",
            "Epoch 2 batch 21: loss = 525.97412109375\n",
            "Epoch 2 batch 22: loss = 468.7027893066406\n",
            "Epoch 2 batch 23: loss = 771.7164916992188\n",
            "Epoch 2 batch 24: loss = 471.72747802734375\n",
            "Epoch 2 batch 25: loss = 696.6389770507812\n",
            "Epoch 2 batch 26: loss = 408.36572265625\n",
            "Epoch 2 batch 27: loss = 674.1119384765625\n",
            "Epoch 2 batch 28: loss = 458.72857666015625\n",
            "Epoch 2 batch 29: loss = 435.6824951171875\n",
            "Epoch 2 batch 30: loss = 557.8643798828125\n",
            "Epoch 2 batch 31: loss = 655.9219970703125\n",
            "Epoch 2 batch 32: loss = 766.58203125\n",
            "Epoch 2 batch 33: loss = 711.4954833984375\n",
            "Epoch 2 batch 34: loss = 751.7344970703125\n",
            "Epoch 2 batch 35: loss = 796.0156860351562\n",
            "Epoch 2 batch 36: loss = 515.8739624023438\n",
            "Epoch 2 batch 37: loss = 980.7334594726562\n",
            "Epoch 2 batch 38: loss = 904.8812255859375\n",
            "Epoch 2 batch 39: loss = 712.4952392578125\n",
            "Epoch 2 batch 40: loss = 1170.53564453125\n",
            "Epoch 2 batch 41: loss = 720.9876098632812\n",
            "Epoch 2 batch 42: loss = 644.194091796875\n",
            "Epoch 2 batch 43: loss = 883.367431640625\n",
            "Epoch 2 batch 44: loss = 445.2062683105469\n",
            "Epoch 2 batch 45: loss = 574.9672241210938\n",
            "Epoch 2 batch 46: loss = 659.5114135742188\n",
            "Epoch 2 batch 47: loss = 479.71295166015625\n",
            "Epoch 2 batch 48: loss = 488.8817443847656\n",
            "Epoch 2 batch 49: loss = 947.1246337890625\n",
            "Epoch 3 batch 0: loss = 743.71240234375\n",
            "Epoch 3 batch 1: loss = 790.9765625\n",
            "Epoch 3 batch 2: loss = 530.1693725585938\n",
            "Epoch 3 batch 3: loss = 714.810302734375\n",
            "Epoch 3 batch 4: loss = 511.68524169921875\n",
            "Epoch 3 batch 5: loss = 662.381591796875\n",
            "Epoch 3 batch 6: loss = 314.6419677734375\n",
            "Epoch 3 batch 7: loss = 755.4196166992188\n",
            "Epoch 3 batch 8: loss = 907.3657836914062\n",
            "Epoch 3 batch 9: loss = 676.4025268554688\n",
            "Epoch 3 batch 10: loss = 550.1937866210938\n",
            "Epoch 3 batch 11: loss = 306.075927734375\n",
            "Epoch 3 batch 12: loss = 522.5496826171875\n",
            "Epoch 3 batch 13: loss = 517.0067749023438\n",
            "Epoch 3 batch 14: loss = 631.8094482421875\n",
            "Epoch 3 batch 15: loss = 717.1249389648438\n",
            "Epoch 3 batch 16: loss = 945.9232177734375\n",
            "Epoch 3 batch 17: loss = 476.902099609375\n",
            "Epoch 3 batch 18: loss = 686.980224609375\n",
            "Epoch 3 batch 19: loss = 716.7753295898438\n",
            "Epoch 3 batch 20: loss = 1146.0927734375\n",
            "Epoch 3 batch 21: loss = 685.9328002929688\n",
            "Epoch 3 batch 22: loss = 631.7796630859375\n",
            "Epoch 3 batch 23: loss = 679.195556640625\n",
            "Epoch 3 batch 24: loss = 642.0369262695312\n",
            "Epoch 3 batch 25: loss = 633.320068359375\n",
            "Epoch 3 batch 26: loss = 491.9661560058594\n",
            "Epoch 3 batch 27: loss = 884.0889892578125\n",
            "Epoch 3 batch 28: loss = 590.117919921875\n",
            "Epoch 3 batch 29: loss = 766.7726440429688\n",
            "Epoch 3 batch 30: loss = 918.2945556640625\n",
            "Epoch 3 batch 31: loss = 1051.129150390625\n",
            "Epoch 3 batch 32: loss = 547.17626953125\n",
            "Epoch 3 batch 33: loss = 436.8050842285156\n",
            "Epoch 3 batch 34: loss = 686.2350463867188\n",
            "Epoch 3 batch 35: loss = 661.806640625\n",
            "Epoch 3 batch 36: loss = 598.3824462890625\n",
            "Epoch 3 batch 37: loss = 432.468505859375\n",
            "Epoch 3 batch 38: loss = 865.886474609375\n",
            "Epoch 3 batch 39: loss = 460.1492004394531\n",
            "Epoch 3 batch 40: loss = 614.0538330078125\n",
            "Epoch 3 batch 41: loss = 526.631103515625\n",
            "Epoch 3 batch 42: loss = 1023.6231689453125\n",
            "Epoch 3 batch 43: loss = 686.46923828125\n",
            "Epoch 3 batch 44: loss = 718.3486938476562\n",
            "Epoch 3 batch 45: loss = 446.8912658691406\n",
            "Epoch 3 batch 46: loss = 667.495361328125\n",
            "Epoch 3 batch 47: loss = 512.220703125\n",
            "Epoch 3 batch 48: loss = 560.8099365234375\n",
            "Epoch 3 batch 49: loss = 488.47003173828125\n",
            "Epoch 4 batch 0: loss = 683.273193359375\n",
            "Epoch 4 batch 1: loss = 564.08203125\n",
            "Epoch 4 batch 2: loss = 371.25823974609375\n",
            "Epoch 4 batch 3: loss = 634.7157592773438\n",
            "Epoch 4 batch 4: loss = 845.8270263671875\n",
            "Epoch 4 batch 5: loss = 757.1424560546875\n",
            "Epoch 4 batch 6: loss = 544.9909057617188\n",
            "Epoch 4 batch 7: loss = 514.220703125\n",
            "Epoch 4 batch 8: loss = 764.2852783203125\n",
            "Epoch 4 batch 9: loss = 874.5364990234375\n",
            "Epoch 4 batch 10: loss = 765.2666015625\n",
            "Epoch 4 batch 11: loss = 577.2393798828125\n",
            "Epoch 4 batch 12: loss = 381.00665283203125\n",
            "Epoch 4 batch 13: loss = 580.3112182617188\n",
            "Epoch 4 batch 14: loss = 699.85986328125\n",
            "Epoch 4 batch 15: loss = 501.09112548828125\n",
            "Epoch 4 batch 16: loss = 496.13433837890625\n",
            "Epoch 4 batch 17: loss = 983.80615234375\n",
            "Epoch 4 batch 18: loss = 620.83740234375\n",
            "Epoch 4 batch 19: loss = 600.6948852539062\n",
            "Epoch 4 batch 20: loss = 735.133544921875\n",
            "Epoch 4 batch 21: loss = 620.3772583007812\n",
            "Epoch 4 batch 22: loss = 1101.7081298828125\n",
            "Epoch 4 batch 23: loss = 733.57373046875\n",
            "Epoch 4 batch 24: loss = 811.5900268554688\n",
            "Epoch 4 batch 25: loss = 615.576904296875\n",
            "Epoch 4 batch 26: loss = 485.5517883300781\n",
            "Epoch 4 batch 27: loss = 499.58929443359375\n",
            "Epoch 4 batch 28: loss = 686.0055541992188\n",
            "Epoch 4 batch 29: loss = 761.4005737304688\n",
            "Epoch 4 batch 30: loss = 857.4351806640625\n",
            "Epoch 4 batch 31: loss = 682.8630981445312\n",
            "Epoch 4 batch 32: loss = 648.3797607421875\n",
            "Epoch 4 batch 33: loss = 681.970458984375\n",
            "Epoch 4 batch 34: loss = 448.267578125\n",
            "Epoch 4 batch 35: loss = 530.5045166015625\n",
            "Epoch 4 batch 36: loss = 626.4227905273438\n",
            "Epoch 4 batch 37: loss = 484.02752685546875\n",
            "Epoch 4 batch 38: loss = 692.6705932617188\n",
            "Epoch 4 batch 39: loss = 446.21734619140625\n",
            "Epoch 4 batch 40: loss = 1001.5765380859375\n",
            "Epoch 4 batch 41: loss = 982.4757690429688\n",
            "Epoch 4 batch 42: loss = 369.2885437011719\n",
            "Epoch 4 batch 43: loss = 324.286865234375\n",
            "Epoch 4 batch 44: loss = 654.4898681640625\n",
            "Epoch 4 batch 45: loss = 730.09423828125\n",
            "Epoch 4 batch 46: loss = 334.35516357421875\n",
            "Epoch 4 batch 47: loss = 526.7149658203125\n",
            "Epoch 4 batch 48: loss = 708.2191162109375\n",
            "Epoch 4 batch 49: loss = 786.1851196289062\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CstExs3Savqn"
      },
      "source": [
        " test_x = np.array([[-0.0405441 ,  0.06636364, -0.32356227, -0.06916996, -0.03435197,\n",
        "        0.05563625, -0.03475696,  0.02682186, -0.37171335, -0.21419304,\n",
        "       -0.33569506,  0.10143217, -0.21172912]]).astype('float32')\n",
        "\n",
        "df_test_x = pd.DataFrame(test_x)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7qADc_KcJI-"
      },
      "source": [
        "import csv\n",
        "\n",
        "with open('test.csv', 'w', newline='') as csvfile:\n",
        "    spamwriter = csv.writer(csvfile, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
        "    spamwriter.writerow(df_test_x.columns)\n",
        "    spamwriter.writerow([-0.0405441 ,  0.06636364, -0.32356227, -0.06916996, -0.03435197,\n",
        "        0.05563625, -0.03475696,  0.02682186, -0.37171335, -0.21419304,\n",
        "       -0.33569506,  0.10143217, -0.21172912])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcrHdbJxAHh0"
      },
      "source": [
        "# **Create BentoService for model serving**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_T8YQRjALqg",
        "outputId": "1e03fc29-31e8-4deb-8e84-3fd2259b0989"
      },
      "source": [
        "%%writefile paddle_linear_regression.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import bentoml\n",
        "from bentoml import env, artifacts, api, BentoService\n",
        "from bentoml.adapters import DataframeInput\n",
        "from bentoml.frameworks.paddle import PaddlePaddleModelArtifact\n",
        "\n",
        "@env(infer_pip_packages=True)\n",
        "@artifacts([PaddlePaddleModelArtifact('model')])\n",
        "class PaddleLinearRegression(bentoml.BentoService):\n",
        "\n",
        "  @api(input=DataframeInput(), batch=True)\n",
        "  def predict(self, df: pd.DataFrame):\n",
        "      #return self.artifacts.model(df.to_numpy().astype('float32')).numpy()\n",
        "\n",
        "        input_data = df.to_numpy().astype('float32')\n",
        "\n",
        "        predictor = self.artifacts.model\n",
        "        input_names = predictor.get_input_names()\n",
        "        input_handle = predictor.get_input_handle(input_names[0])\n",
        "\n",
        "        input_handle.reshape(input_data.shape)\n",
        "        input_handle.copy_from_cpu(input_data)\n",
        "\n",
        "        predictor.run()\n",
        "\n",
        "        output_names = predictor.get_output_names()\n",
        "        output_handle = predictor.get_output_handle(output_names[0])\n",
        "        output_data = output_handle.copy_to_cpu()\n",
        "\n",
        "        return output_data"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting paddle_linear_regression.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESc4D_muCWNx",
        "outputId": "56c387dd-d04a-4379-fede-849728ed3c61"
      },
      "source": [
        "# 1) import the custom BentoService defined above\n",
        "from paddle_linear_regression import PaddleLinearRegression\n",
        "\n",
        "# 2) `pack` it with required artifacts\n",
        "bento_svc = PaddleLinearRegression()\n",
        "bento_svc.pack('model', model)\n",
        "\n",
        "# 3) save your BentoSerivce\n",
        "saved_path = bento_svc.save()\n",
        "\n",
        "bento_svc.predict(df_test_x)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2021-03-19 23:40:00,935] WARNING - pip package requirement `bentoml==0.7.8` not found in current python environment\n",
            "[2021-03-19 23:40:00,950] WARNING - pip package requirement `paddlepaddle` not found in current python environment\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-03-19 23:40:00,999 - INFO - Context impl SQLiteImpl.\n",
            "2021-03-19 23:40:01,001 - INFO - Will assume non-transactional DDL.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[2021-03-19 23:40:01,425] WARNING - Saved BentoService bundle version mismatch: loading BentoService bundle create with BentoML version 0.7.8, but loading from BentoML version 0.7.8+404.g2d929d6\n",
            "[2021-03-19 23:40:01,493] INFO - BentoService bundle 'PaddleLinearRegression:20210319234001_3DFAC6' saved to: /root/bentoml/repository/PaddleLinearRegression/20210319234001_3DFAC6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.66201186]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvUU0k0JCxYk"
      },
      "source": [
        "# **REST API Model Serving**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeJEIDyj_xGK",
        "outputId": "e8a10ca6-a584-4581-d1bf-a978a37344b8"
      },
      "source": [
        "!bentoml serve PaddleLinearRegression:latest"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
            "  \"\"\")\n",
            "[2021-03-19 06:39:56,867] INFO - Getting latest version PaddleLinearRegression:20210319063952_A0B168\n",
            "[2021-03-19 06:39:57,067] INFO - Starting BentoML API server in development mode..\n",
            "[2021-03-19 06:39:57,437] WARNING - Using BentoML not from official PyPI release. In order to find the same version of BentoML when deploying your BentoService, you must set the 'core/bentoml_deploy_version' config to a http/git location of your BentoML fork, e.g.: 'bentoml_deploy_version = git+https://github.com/{username}/bentoml.git@{branch}'\n",
            "[2021-03-19 06:39:57,451] WARNING - Saved BentoService bundle version mismatch: loading BentoService bundle create with BentoML version 0.7.8, but loading from BentoML version 0.7.8+403.gc8dc7b2\n",
            "/usr/local/lib/python3.7/dist-packages/paddle/fluid/backward.py:1640: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
            "  return list(x) if isinstance(x, collections.Sequence) else [x]\n",
            " * Serving Flask app \"PaddleLinearRegression\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n",
            "2021-03-19 06:39:59,196 - INFO -  * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPoKbR6cCq8_"
      },
      "source": [
        "If you are running this notebook from Google Colab, you can start the dev server with --run-with-ngrok option, to gain acccess to the API endpoint via a public endpoint managed by ngrok:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RodE8ooiCqRw",
        "outputId": "287d4798-2d07-4195-d5c6-e078484eed98"
      },
      "source": [
        "!bentoml serve PaddleLinearRegression:latest --run-with-ngrok"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
            "  \"\"\")\n",
            "[2021-03-19 23:42:11,015] INFO - Getting latest version PaddleLinearRegression:20210319234001_3DFAC6\n",
            "[2021-03-19 23:42:11,255] INFO - Starting BentoML API server in development mode..\n",
            "[2021-03-19 23:42:11,627] WARNING - Using BentoML not from official PyPI release. In order to find the same version of BentoML when deploying your BentoService, you must set the 'core/bentoml_deploy_version' config to a http/git location of your BentoML fork, e.g.: 'bentoml_deploy_version = git+https://github.com/{username}/bentoml.git@{branch}'\n",
            "[2021-03-19 23:42:11,644] WARNING - Saved BentoService bundle version mismatch: loading BentoService bundle create with BentoML version 0.7.8, but loading from BentoML version 0.7.8+404.g2d929d6\n",
            "/usr/local/lib/python3.7/dist-packages/paddle/fluid/backward.py:1640: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
            "  return list(x) if isinstance(x, collections.Sequence) else [x]\n",
            "I0319 23:42:13.786195   382 analysis_predictor.cc:155] Profiler is deactivated, and no profiling report will be generated.\n",
            "\u001b[1m\u001b[35m--- Running analysis [ir_graph_build_pass]\u001b[0m\n",
            "\u001b[1m\u001b[35m--- Running analysis [ir_graph_clean_pass]\u001b[0m\n",
            "\u001b[1m\u001b[35m--- Running analysis [ir_analysis_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [simplify_with_basic_ops_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [attention_lstm_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [seqconv_eltadd_relu_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [seqpool_cvm_concat_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [mul_lstm_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [fc_gru_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [mul_gru_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [seq_concat_fc_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [squeeze2_matmul_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [reshape2_matmul_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [flatten2_matmul_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [map_matmul_to_mul_pass]\u001b[0m\n",
            "I0319 23:42:13.802947   382 graph_pattern_detector.cc:101] ---  detected 1 subgraphs\n",
            "\u001b[32m--- Running IR pass [fc_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [repeated_fc_relu_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [squared_mat_sub_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [conv_bn_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [conv_eltwiseadd_bn_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [conv_transpose_bn_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [conv_transpose_eltwiseadd_bn_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [is_test_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [runtime_context_cache_pass]\u001b[0m\n",
            "\u001b[1m\u001b[35m--- Running analysis [ir_params_sync_among_devices_pass]\u001b[0m\n",
            "\u001b[1m\u001b[35m--- Running analysis [adjust_cudnn_workspace_size_pass]\u001b[0m\n",
            "\u001b[1m\u001b[35m--- Running analysis [inference_op_replace_pass]\u001b[0m\n",
            "\u001b[1m\u001b[35m--- Running analysis [memory_optimize_pass]\u001b[0m\n",
            "I0319 23:42:13.804738   382 memory_optimize_pass.cc:200] Cluster name : linear_1.tmp_2  size: 4\n",
            "I0319 23:42:13.804759   382 memory_optimize_pass.cc:200] Cluster name : linear_1.tmp_1  size: 4\n",
            "I0319 23:42:13.804787   382 memory_optimize_pass.cc:200] Cluster name : x  size: 52\n",
            "I0319 23:42:13.804796   382 memory_optimize_pass.cc:200] Cluster name : x_0  size: 52\n",
            "\u001b[1m\u001b[35m--- Running analysis [ir_graph_to_program_pass]\u001b[0m\n",
            "I0319 23:42:13.806308   382 analysis_predictor.cc:598] ======= optimize end =======\n",
            "I0319 23:42:13.806350   382 naive_executor.cc:107] ---  skip [feed], feed -> x\n",
            "I0319 23:42:13.806476   382 naive_executor.cc:107] ---  skip [linear_1.tmp_1], fetch -> fetch\n",
            " * Serving Flask app \"PaddleLinearRegression\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n",
            "2021-03-19 23:42:14,253 - INFO -  * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
            "[2021-03-19 23:42:14,537] INFO -  * Running on http://f3eae3fb9d5c.ngrok.io\n",
            "[2021-03-19 23:42:14,537] INFO -  * Traffic stats available on http://127.0.0.1:4040\n",
            "2021-03-19 23:42:47,894 - INFO - 127.0.0.1 - - [19/Mar/2021 23:42:47] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "2021-03-19 23:42:48,054 - INFO - 127.0.0.1 - - [19/Mar/2021 23:42:48] \"\u001b[37mGET /static_content/main.css HTTP/1.1\u001b[0m\" 200 -\n",
            "2021-03-19 23:42:48,076 - INFO - 127.0.0.1 - - [19/Mar/2021 23:42:48] \"\u001b[37mGET /static_content/readme.css HTTP/1.1\u001b[0m\" 200 -\n",
            "2021-03-19 23:42:48,147 - INFO - 127.0.0.1 - - [19/Mar/2021 23:42:48] \"\u001b[37mGET /static_content/marked.min.js HTTP/1.1\u001b[0m\" 200 -\n",
            "2021-03-19 23:42:48,153 - INFO - 127.0.0.1 - - [19/Mar/2021 23:42:48] \"\u001b[37mGET /static_content/swagger-ui-bundle.js HTTP/1.1\u001b[0m\" 200 -\n",
            "2021-03-19 23:42:48,159 - INFO - 127.0.0.1 - - [19/Mar/2021 23:42:48] \"\u001b[37mGET /static_content/swagger-ui.css HTTP/1.1\u001b[0m\" 200 -\n",
            "2021-03-19 23:42:48,831 - INFO - 127.0.0.1 - - [19/Mar/2021 23:42:48] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "2021-03-19 23:42:48,886 - INFO - 127.0.0.1 - - [19/Mar/2021 23:42:48] \"\u001b[37mGET /docs.json HTTP/1.1\u001b[0m\" 200 -\n",
            "2021-03-19 23:42:48,920 - INFO - 127.0.0.1 - - [19/Mar/2021 23:42:48] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "2021-03-19 23:42:49,215 - INFO - 127.0.0.1 - - [19/Mar/2021 23:42:49] \"\u001b[37mGET /static_content/readme.css HTTP/1.1\u001b[0m\" 200 -\n",
            "[2021-03-19 23:43:03,464] ERROR - Error caught in API function:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/bentoml/service/inference_api.py\", line 177, in wrapped_func\n",
            "    return self._user_func(*args, **kwargs)\n",
            "  File \"/root/bentoml/repository/PaddleLinearRegression/20210319234001_3DFAC6/PaddleLinearRegression/paddle_linear_regression.py\", line 17, in predict\n",
            "    input_data = df.to_numpy().astype('float32')\n",
            "AttributeError: 'NoneType' object has no attribute 'to_numpy'\n",
            "2021-03-19 23:43:03.638699: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-03-19 23:43:05,368 - INFO - 127.0.0.1 - - [19/Mar/2021 23:43:05] \"\u001b[31m\u001b[1mPOST /predict HTTP/1.1\u001b[0m\" 400 -\n",
            "[2021-03-19 23:43:13,486] ERROR - Error caught in API function:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/bentoml/service/inference_api.py\", line 177, in wrapped_func\n",
            "    return self._user_func(*args, **kwargs)\n",
            "  File \"/root/bentoml/repository/PaddleLinearRegression/20210319234001_3DFAC6/PaddleLinearRegression/paddle_linear_regression.py\", line 17, in predict\n",
            "    input_data = df.to_numpy().astype('float32')\n",
            "AttributeError: 'NoneType' object has no attribute 'to_numpy'\n",
            "2021-03-19 23:43:13,487 - INFO - 127.0.0.1 - - [19/Mar/2021 23:43:13] \"\u001b[31m\u001b[1mPOST /predict HTTP/1.1\u001b[0m\" 400 -\n",
            "[2021-03-19 23:43:19,461] ERROR - Error caught in API function:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/bentoml/service/inference_api.py\", line 177, in wrapped_func\n",
            "    return self._user_func(*args, **kwargs)\n",
            "  File \"/root/bentoml/repository/PaddleLinearRegression/20210319234001_3DFAC6/PaddleLinearRegression/paddle_linear_regression.py\", line 17, in predict\n",
            "    input_data = df.to_numpy().astype('float32')\n",
            "AttributeError: 'NoneType' object has no attribute 'to_numpy'\n",
            "2021-03-19 23:43:19,462 - INFO - 127.0.0.1 - - [19/Mar/2021 23:43:19] \"\u001b[31m\u001b[1mPOST /predict HTTP/1.1\u001b[0m\" 400 -\n",
            "[2021-03-19 23:43:26,241] INFO - {'service_name': 'PaddleLinearRegression', 'service_version': '20210319234001_3DFAC6', 'api': 'predict', 'task': {'data': '[[-0.0405441,0.06636364,-0.32356227,-0.06916996,-0.03435197,0.05563625,-0.03475696,0.02682186,-0.37171335,-0.21419304,-0.33569506,0.10143217,-0.21172912]]', 'task_id': '1763ef1a-44ec-4044-a734-4dacf4f7d05c', 'batch': 1, 'http_headers': (('Host', 'f3eae3fb9d5c.ngrok.io'), ('User-Agent', 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36'), ('Content-Length', '154'), ('Accept', '*/*'), ('Accept-Encoding', 'gzip, deflate'), ('Accept-Language', 'en-US,en;q=0.9'), ('Content-Type', 'application/json'), ('Origin', 'http://f3eae3fb9d5c.ngrok.io'), ('Referer', 'http://f3eae3fb9d5c.ngrok.io/'), ('X-Forwarded-For', '2601:647:cb00:f20:a97d:2fe2:7dee:64be'), ('X-Forwarded-Proto', 'http'))}, 'result': {'data': '[[0.6620118618011475]]', 'http_status': 200, 'http_headers': (('Content-Type', 'application/json'),)}, 'request_id': '1763ef1a-44ec-4044-a734-4dacf4f7d05c'}\n",
            "2021-03-19 23:43:26,242 - INFO - 127.0.0.1 - - [19/Mar/2021 23:43:26] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMCrkYb5DDHB"
      },
      "source": [
        "# **Make request to the REST server**\n",
        "\n",
        "*After navigating to the location of this notebook, copy and paste the following code to your terminal and run it to make request*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMyLXOIUDXSn"
      },
      "source": [
        "curl -i \\\n",
        "--request POST \\\n",
        "--header \"Content-Type: text/csv\" \\\n",
        "-d @test.csv \\\n",
        "localhost:5000/predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RA0JpPjDMt8"
      },
      "source": [
        "# **Containerize model server with Docker**\n",
        "\n",
        "One common way of distributing this model API server for production deployment, is via Docker containers. And BentoML provides a convenient way to do that.\n",
        "\n",
        "Note that docker is **not available in Google Colab**. You will need to download and run this notebook locally to try out this containerization with docker feature.\n",
        "\n",
        "If you already have docker configured, simply run the follow command to product a docker container serving the PaddleLinearRegression prediction service created above:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKUGBMNWDJnr"
      },
      "source": [
        "!bentoml containerize PaddleLinearRegression:latest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nyRChqMDwv4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da95549c-1901-484b-8489-d9b0c9706105"
      },
      "source": [
        "!docker run --rm -p 5000:5000 PaddleLinearRegression:20210306050051_766D0A"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: docker: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrnR2hRDD7xf"
      },
      "source": [
        "# **Load Saved Bento Service**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfxsxBRmD1Tx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3dca212-9359-4bd0-b131-ed766576418d"
      },
      "source": [
        "#TODO ADD INPUT\n",
        "from bentoml import load\n",
        "\n",
        "svc = load(saved_path)\n",
        "\n",
        "input = pd.DataFrame([[-0.0405441 ,  0.06636364, -0.32356227, -0.06916996, -0.03435197,\n",
        "        0.05563625, -0.03475696,  0.02682186, -0.37171335, -0.21419304,\n",
        "       -0.33569506,  0.10143217, -0.21172912]]).astype('float32')\n",
        "\n",
        "print(svc.predict(input))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2021-03-06 05:05:25,666] WARNING - Saved BentoService bundle version mismatch: loading BentoService bundle create with BentoML version 0.7.8, but loading from BentoML version 0.7.8+402.g8c47823\n",
            "[2021-03-06 05:05:25,669] WARNING - Module `paddle_linear_regression` already loaded, using existing imported module.\n",
            "[2021-03-06 05:05:25,680] WARNING - pip package requirement pandas already exist\n",
            "[2021-03-06 05:05:25,681] WARNING - pip package requirement paddlepaddle already exist\n",
            "[[0.85793805]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlGTKeMnEEyE"
      },
      "source": [
        "# **Launch inference job from CLI**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fgqIWWIEIva",
        "outputId": "81362930-5b0c-4f7c-a715-8089f323b722"
      },
      "source": [
        "!bentoml run PaddleLinearRegression:latest predict --format csv --input-file test.csv"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
            "  \"\"\")\n",
            "[2021-03-19 23:40:10,724] INFO - Getting latest version PaddleLinearRegression:20210319234001_3DFAC6\n",
            "[2021-03-19 23:40:11,089] WARNING - Using BentoML not from official PyPI release. In order to find the same version of BentoML when deploying your BentoService, you must set the 'core/bentoml_deploy_version' config to a http/git location of your BentoML fork, e.g.: 'bentoml_deploy_version = git+https://github.com/{username}/bentoml.git@{branch}'\n",
            "[2021-03-19 23:40:11,106] WARNING - Saved BentoService bundle version mismatch: loading BentoService bundle create with BentoML version 0.7.8, but loading from BentoML version 0.7.8+404.g2d929d6\n",
            "/usr/local/lib/python3.7/dist-packages/paddle/fluid/backward.py:1640: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
            "  return list(x) if isinstance(x, collections.Sequence) else [x]\n",
            "I0319 23:40:13.007472   346 analysis_predictor.cc:155] Profiler is deactivated, and no profiling report will be generated.\n",
            "\u001b[1m\u001b[35m--- Running analysis [ir_graph_build_pass]\u001b[0m\n",
            "\u001b[1m\u001b[35m--- Running analysis [ir_graph_clean_pass]\u001b[0m\n",
            "\u001b[1m\u001b[35m--- Running analysis [ir_analysis_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [simplify_with_basic_ops_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [attention_lstm_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [seqconv_eltadd_relu_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [seqpool_cvm_concat_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [mul_lstm_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [fc_gru_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [mul_gru_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [seq_concat_fc_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [squeeze2_matmul_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [reshape2_matmul_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [flatten2_matmul_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [map_matmul_to_mul_pass]\u001b[0m\n",
            "I0319 23:40:13.020429   346 graph_pattern_detector.cc:101] ---  detected 1 subgraphs\n",
            "\u001b[32m--- Running IR pass [fc_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [repeated_fc_relu_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [squared_mat_sub_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [conv_bn_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [conv_eltwiseadd_bn_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [conv_transpose_bn_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [conv_transpose_eltwiseadd_bn_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [is_test_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [runtime_context_cache_pass]\u001b[0m\n",
            "\u001b[1m\u001b[35m--- Running analysis [ir_params_sync_among_devices_pass]\u001b[0m\n",
            "\u001b[1m\u001b[35m--- Running analysis [adjust_cudnn_workspace_size_pass]\u001b[0m\n",
            "\u001b[1m\u001b[35m--- Running analysis [inference_op_replace_pass]\u001b[0m\n",
            "\u001b[1m\u001b[35m--- Running analysis [memory_optimize_pass]\u001b[0m\n",
            "I0319 23:40:13.021656   346 memory_optimize_pass.cc:200] Cluster name : linear_1.tmp_2  size: 4\n",
            "I0319 23:40:13.021672   346 memory_optimize_pass.cc:200] Cluster name : linear_1.tmp_1  size: 4\n",
            "I0319 23:40:13.021678   346 memory_optimize_pass.cc:200] Cluster name : x  size: 52\n",
            "I0319 23:40:13.021684   346 memory_optimize_pass.cc:200] Cluster name : x_0  size: 52\n",
            "\u001b[1m\u001b[35m--- Running analysis [ir_graph_to_program_pass]\u001b[0m\n",
            "I0319 23:40:13.023006   346 analysis_predictor.cc:598] ======= optimize end =======\n",
            "I0319 23:40:13.023041   346 naive_executor.cc:107] ---  skip [feed], feed -> x\n",
            "I0319 23:40:13.023128   346 naive_executor.cc:107] ---  skip [linear_1.tmp_1], fetch -> fetch\n",
            "2021-03-19 23:40:13.652852: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "[2021-03-19 23:40:15,472] INFO - {'service_name': 'PaddleLinearRegression', 'service_version': '20210319234001_3DFAC6', 'api': 'predict', 'task': {'data': '0,1,2,3,4,5,6,7,8,9,10,11,12\\r\\n-0.0405441,0.06636364,-0.32356227,-0.06916996,-0.03435197,0.05563625,-0.03475696,0.02682186,-0.37171335,-0.21419304,-0.33569506,0.10143217,-0.21172912\\r\\n', 'task_id': '1be47c78-15d7-4869-9e16-30c2daea5bc2', 'batch': 1, 'cli_args': ('--format', 'csv', '--input-file', 'test.csv'), 'inference_job_args': {}}, 'result': {'data': '[[0.6620118618011475]]', 'http_status': 200, 'http_headers': (('Content-Type', 'application/json'),)}, 'request_id': '1be47c78-15d7-4869-9e16-30c2daea5bc2'}\n",
            "[[0.6620118618011475]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jb-srm9RENeh"
      },
      "source": [
        "# **Deployment Options**\n",
        "\n",
        "If you are at a small team with limited engineering or DevOps resources, try out automated deployment with BentoML CLI, currently supporting AWS Lambda, AWS SageMaker, and Azure Functions:\n",
        "\n",
        "* [AWS Lambda Deployment Guide](https://docs.bentoml.org/en/latest/deployment/aws_lambda.html)\n",
        "* [AWS SageMaker Deployment Guide](https://docs.bentoml.org/en/latest/deployment/aws_sagemaker.html)\n",
        "* [Azure Functions Deployment Guide](https://docs.bentoml.org/en/latest/deployment/azure_functions.html)\n",
        "\n",
        "If the cloud platform you are working with is not on the list above, try out these step-by-step guide on manually deploying BentoML packaged model to cloud platforms:\n",
        "\n",
        "* [AWS ECS Deployment](https://docs.bentoml.org/en/latest/deployment/aws_ecs.html)\n",
        "* [Google Cloud Run Deployment](https://docs.bentoml.org/en/latest/deployment/google_cloud_run.html)\n",
        "* [Azure container instance Deployment](https://docs.bentoml.org/en/latest/deployment/azure_container_instance.html)\n",
        "* [Heroku Deployment](https://docs.bentoml.org/en/latest/deployment/heroku.html)\n",
        "\n",
        "Lastly, if you have a DevOps or ML Engineering team who's operating a Kubernetes or OpenShift cluster, use the following guides as references for implementating your deployment strategy:\n",
        "\n",
        "* [Kubernetes Deployment](https://docs.bentoml.org/en/latest/deployment/kubernetes.html)\n",
        "* [Knative Deployment](https://docs.bentoml.org/en/latest/deployment/knative.html)\n",
        "* [Kubeflow Deployment](https://docs.bentoml.org/en/latest/deployment/kubeflow.html)\n",
        "* [KFServing Deployment](https://docs.bentoml.org/en/latest/deployment/kfserving.html)\n",
        "* [Clipper.ai Deployment Guide](https://docs.bentoml.org/en/latest/deployment/clipper.html)"
      ]
    }
  ]
}
